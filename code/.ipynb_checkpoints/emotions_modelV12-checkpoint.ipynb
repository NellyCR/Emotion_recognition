{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# I previosuly explored the dataset in a jupyter notebook called Dataset_overview \n",
    "\n",
    "data = pd.read_csv('/Users/nelly/Facial_emotion_recogniton/fer2013.csv')\n",
    "\n",
    "\n",
    "# Split the data into train and test\n",
    "\n",
    "X_train, train_y , X_test , test_y = [],[],[],[]\n",
    "\n",
    "for index,row in data.iterrows():\n",
    "    pixls = row['pixels'].split(\" \") # Pixels are separated by a space, we store them as a list called pixls\n",
    "    try:\n",
    "        if 'Training' in row ['Usage']: # Assign values to train sets\n",
    "            X_train.append(np.array(pixls,'float32')) # pixels converted to float numpy arrays (needed for keras and normalization)\n",
    "            train_y.append(row['emotion']) # our target\n",
    "        elif 'PublicTest' in row['Usage']: # Assign values to test sets\n",
    "            test_y.append(row['emotion']) \n",
    "            X_test.append(np.array(pixls,'float32'))  \n",
    "    except: \n",
    "        print(f'Error found: index {index} row :{row}')        \n",
    "\n",
    "\n",
    "\n",
    "# Convert test and train sets into numpy arrays (needed for keras and normalization)\n",
    "\n",
    "X_train= np.array( X_train ,'float32')\n",
    "X_test= np.array( X_test ,'float32')\n",
    "train_y= np.array( train_y ,'float32')\n",
    "test_y= np.array( test_y ,'float32')\n",
    "\n",
    "# Normalization: substract the mean and divide it by the standard deviation (to convert all from 0 to 1 values)\n",
    "\n",
    "X_train = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
    "X_test = (X_test - np.mean(X_test, axis=0)) / np.std(X_test, axis=0)  \n",
    "\n",
    "# Model\n",
    "\n",
    "num_features=64 # filters\n",
    "num_labels=7 # the emotions that we want to predict\n",
    "batch_size=32 # Number of samples processed before the model is updated\n",
    "epochs=1 # Number of complete passes through the training dataset\n",
    "width,height = 48,48  # to reshape image size\n",
    "\n",
    "# Reshape \"X\" for keras using the width,height = 48,48\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],width,height,1) # 0 is for the row, 1 means one image will have this widht and height\n",
    "X_test = X_test.reshape(X_test.shape[0],width,height,1)\n",
    "\n",
    "\n",
    "# Change \"Y\" to categorical (in order to use categorical_crossentropy later)\n",
    "# It converts an array into a matrix : we'll have as many colums as they are classes kinda like dummies in numpy ( the rows stay the same)\n",
    "\n",
    "train_y=np_utils.to_categorical(train_y,num_classes=num_labels)\n",
    "test_y=np_utils.to_categorical(test_y,num_classes=num_labels)\n",
    "\n",
    "# Choose model \n",
    "\n",
    "model= Sequential() # a linear stack of layers ( no shared layers or multiple inputs or outputs)\n",
    "\n",
    "# Add convolutional and pooling layers\n",
    "\n",
    "# 1st layer \n",
    "\n",
    "model.add(Conv2D(64,kernel_size=(3,3),input_shape=(48,48,1),activation='relu')) # shape not for all the row just (width,height,1)\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2))) # Downsamples the input representation\n",
    "model.add(BatchNormalization())   # Instead of Dropout to standardize the outputs of a hidden layer\n",
    "\n",
    "# 2nd layer \n",
    "\n",
    "model.add(Conv2D(128,(3,3), activation='relu'))  # 128 filters\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2))) \n",
    "model.add(BatchNormalization())  \n",
    "\n",
    "# 3rd layer \n",
    "\n",
    "model.add(Conv2D(128,(3,3), activation='relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2))) \n",
    "model.add(BatchNormalization()) \n",
    "\n",
    "\n",
    "\n",
    "# 4rd layer \n",
    "\n",
    "model.add(Conv2D(256,(3,3), activation='relu')) # 256 filters\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2))) \n",
    "model.add(BatchNormalization()) \n",
    "\n",
    "# Flattening and adding two fully connected layers\n",
    "\n",
    "model.add(Flatten()) # to make a big vector for dense layer\n",
    "\n",
    "model.add(Dense(1024,activation='relu'))  # 1024 filters\n",
    "model.add(BatchNormalization()) \n",
    "\n",
    "model.add(Dense(7, activation=\"softmax\")) # Final layer : is softclas because we're doing multiclassification (7 labels/emotions)\n",
    "\n",
    "# Compile model: Computes the crossentropy loss between the labels and predictions\n",
    "# Crossentropy is the difference between two probability distributions\n",
    "\n",
    "model.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['accuracy']) \n",
    "\n",
    "# Fit the model\n",
    "\n",
    "model.fit(X_train,train_y,batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=2,  # verbose = 1, which includes both progress bar and one line per epoch. verbose = 0, means silent. verbose = 2, one line per epoch i.e. epoch no./total no. of epochs.\n",
    "    validation_data= (X_test,test_y),\n",
    "    shuffle=True) # to ensure that each data point creates an \"independent\" change on the model, without being biased by the same points before them.\n",
    "\n",
    " # Save model\n",
    "\n",
    "emotions_json= model.to_json()\n",
    "with open (\"emotions12.json\",\"w\") as json_file:\n",
    "  json_file.write(emotions_json)\n",
    "model.save_weights(\"emotions12.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
